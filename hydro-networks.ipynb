{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is hydro-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import heapq\n",
    "from shapely.geometry import Point, LineString, MultiLineString, shape\n",
    "from os.path import join\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime\n",
    "import rasterio\n",
    "import pyproj\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in all the necessary files\n",
    "And do some quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_rivers = 'data/riv_capetown.gpkg'\n",
    "out_rivers = 'data/rivers_processed.gpkg'\n",
    "out_nodes = 'data/nodes.gpkg'\n",
    "out_hydro = 'data/hydro_points.gpkg'\n",
    "\n",
    "in_dem = 'data/DEM.tif'\n",
    "in_gscd = 'data/QMEAN.tif'\n",
    "in_flow_acc = 'data/FlowAcc.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the two rasters\n",
    "dem = rasterio.open(in_dem)\n",
    "gscd = rasterio.open(in_gscd)\n",
    "flow_acc = rasterio.open(in_flow_acc)\n",
    "\n",
    "rivers = gpd.read_file(in_rivers)\n",
    "\n",
    "# project to Mercator so our distances are in metres\n",
    "rivers = rivers.to_crs(epsg=3395)\n",
    "print('All files successfully opened.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(gscd.read(1), cmap='pink')\n",
    "print('GSCD')\n",
    "pyplot.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(dem.read(1), cmap='pink')\n",
    "print('DEM')\n",
    "pyplot.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.plot()\n",
    "print('Rivers with', len(rivers), 'segments')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create network and nodes\n",
    "These will be the main data structures for holding the river network, and the nodes where rivers join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the network and nodes from the HydroSHEDS layer, ready to be stream ordered\n",
    "\n",
    "Structure for network:\n",
    "0   index\n",
    "1   fx\n",
    "2   fy\n",
    "3   lx\n",
    "4   ly\n",
    "5   node index first point\n",
    "6   node index last point\n",
    "7   stream order\n",
    "8   arc length\n",
    "\n",
    "Structure for nodes:\n",
    "0   index\n",
    "1   x\n",
    "2   y\n",
    "3   {} metadata\n",
    "4..   arc indices...\n",
    "\"\"\"\n",
    "\n",
    "# import the start and end end points into the network array of arcs\n",
    "# and simultaneously import them into a separate node array (so two nodes per arc)\n",
    "# there will be duplicate nodes, but they duplicates are ignored later\n",
    "counter = 0\n",
    "length = len(rivers)\n",
    "network = np.empty([length, 9], dtype=np.int32)\n",
    "nodes = []\n",
    "\n",
    "for index, row in rivers.iterrows():\n",
    "    # the geometry variables (int so that they actual match when comparing)\n",
    "    fx = int(row.geometry[0].xy[0][0])\n",
    "    fy = int(row.geometry[0].xy[1][0])\n",
    "    lx = int(row.geometry[0].xy[0][-1])\n",
    "    ly = int(row.geometry[0].xy[1][-1])\n",
    "\n",
    "    # add arc_length as a determinant of how much water contributes downstream\n",
    "    # not sure if it's a good idea going forward...\n",
    "    arc_length = int(row.geometry.length)\n",
    "    \n",
    "    # store the index as a column for easier access\n",
    "    # the last column is for stream order\n",
    "    network[counter] = [counter, fx, fy, lx, ly, -99, -99, -99, arc_length]\n",
    "\n",
    "    # create nodes for the start point and end point separately\n",
    "    nodes.append([2*counter, fx, fy, {}])\n",
    "    nodes.append([2*counter+1, lx, ly, {}])\n",
    "\n",
    "    counter += 1\n",
    "    #print('imported {}'.format(counter))\n",
    "\n",
    "# the most time consuming part of the script\n",
    "# runs through every arc and every node and where there is a match, add\n",
    "#  a reference to the index into the network array\n",
    "# once both nodes have been found for an arc, break that for loop and\n",
    "#  start with the next arc\n",
    "for arc in network:\n",
    "    match_f, match_l = False, False\n",
    "    for node in nodes:\n",
    "        # if the fx and fy values match\n",
    "        if arc[1] == node[1] and arc[2] == node[2]:\n",
    "            # add an index\n",
    "            arc[5] = node[0]\n",
    "            match_f = True\n",
    "        # if the lx and ly values match\n",
    "        elif arc[3] == node[1] and arc[4] == node[2]:\n",
    "            # add an index\n",
    "            arc[6] = node[0]\n",
    "            match_l = True\n",
    "        if match_f and match_l > 1:\n",
    "            # reset and skip to the next arc\n",
    "            break\n",
    "    #print('indexed {}'.format(arc[0]))\n",
    "\n",
    "\n",
    "\n",
    "# for every node, add references to every arc that connects to it\n",
    "for arc in network:\n",
    "    # tell the arc's starting node that it exists\n",
    "    nodes[arc[5]].append(arc[0])\n",
    "    # and tell the arc's ending node that it exists\n",
    "    nodes[arc[6]].append(arc[0])\n",
    "    # print('nodes {}'.format(arc[0]))\n",
    "\n",
    "print('Created network and nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Then calculate Shreve stream order for the network\n",
    "This allows to easily keep track of what is upstream and downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strahler stream order is not used but it's some pretty code so I'm keeping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strahler(arc_index, direction_node_id, network, nodes):\n",
    "    \"\"\"\n",
    "    This function is nearly verbatim from Gleyzer2004 algorithm\n",
    "    But excludes the code to create river segments\n",
    "\n",
    "    :param arc_index: the index of an arc in the networks array\n",
    "    :param direction_node_id: the index of that arc's upstream node\n",
    "    :param network: the network of arcs\n",
    "    :param nodes: contains all the nodes and their connections\n",
    "    \"\"\"\n",
    "    up_stream_orders = []\n",
    "    if len(nodes[direction_node_id]) == 1:\n",
    "        network[arc_index][7] = 1\n",
    "    else:\n",
    "        for arc in nodes[direction_node_id]:\n",
    "            if network[arc][0] != arc_index:\n",
    "                if network[arc][5] != direction_node_id:\n",
    "                    up_stream_orders.append(strahler(arc, network[arc][5], network, nodes))\n",
    "                else:\n",
    "                    up_stream_orders.append(strahler(arc, network[arc][6], network, nodes))\n",
    "        max_order = 0\n",
    "        max_order_count = 0\n",
    "        for order in up_stream_orders:\n",
    "            if order > max_order:\n",
    "                max_order = order\n",
    "                max_order_count = 1\n",
    "            elif order == max_order:\n",
    "                max_order_count += 1\n",
    "        if max_order_count > 1:\n",
    "            network[arc_index][7] = max_order + 1\n",
    "        else:\n",
    "            network[arc_index][7] = max_order\n",
    "    print('so {}'.format(arc_index))\n",
    "    return network[arc_index][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead we use Shreve stream order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shreve(arc_index, direction_node_id, network, nodes):\n",
    "    \"\"\"\n",
    "    Caclulate Shreve stream order instead of Strahler\n",
    "    This ensures that a downstream river is always higher\n",
    "    \"\"\"\n",
    "    up_stream_orders = []\n",
    "    if len(nodes[direction_node_id]) == 5:\n",
    "        network[arc_index][7] = 1\n",
    "    else:\n",
    "        for index, arc in enumerate(nodes[direction_node_id]):\n",
    "            if index >= 4:\n",
    "                if network[arc][0] != arc_index:\n",
    "                    if network[arc][5] != direction_node_id:\n",
    "                        up_stream_orders.append(shreve(arc, network[arc][5], network, nodes))\n",
    "                    else:\n",
    "                        up_stream_orders.append(shreve(arc, network[arc][6], network, nodes))\n",
    "\n",
    "        max_orders = heapq.nlargest(2, up_stream_orders)\n",
    "        if len(max_orders) == 2:\n",
    "            order = 0 + max_orders[0] + max_orders[1]\n",
    "        else:\n",
    "            order = 0 + max(up_stream_orders)\n",
    "\n",
    "        network[arc_index][7] = order\n",
    "\n",
    "    # print('so {}'.format(arc_index))\n",
    "    return network[arc_index][7]\n",
    "\n",
    "for node in nodes:\n",
    "    if len(node) == 5:  # only one arc connected\n",
    "        if node[1] == network[node[4]][3] and node[2] == network[node[4]][4]:\n",
    "            sink = network[node[4]][0]\n",
    "            network[sink][7] = shreve(sink, network[sink][5], network, nodes)\n",
    "            \n",
    "print('Stream ordered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import elevation, gscd etc for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = pyproj.Proj(init='epsg:3395')  # Mercator\n",
    "for node in nodes:\n",
    "    node_proj = proj(*node[1:3], inverse=True)\n",
    "    \n",
    "    node_elevation = next(dem.sample([node_proj]))[0]\n",
    "    node_runoff = next(gscd.sample([node_proj]))[0]\n",
    "    node_flow_acc = next(flow_acc.sample([node_proj]))[0]\n",
    "    \n",
    "    node[3] = {'elevation': node_elevation,\n",
    "               'runoff': node_runoff,\n",
    "               'flow_acc': node_flow_acc}\n",
    "    \n",
    "    ## Add:\n",
    "    # land_type\n",
    "    # et_ref\n",
    "    # precip (times 12!!)\n",
    "    \n",
    "print('metadata imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calc flow accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.DataFrame(columns=['idx', 'xs', 'ys', 'xe', 'ye', 'node_start', 'node_end',\n",
    "                                   'so', 'length'], data=network)\n",
    "rivers_out = rivers.merge(network_df, how='left', left_index=True, right_index=True)\n",
    "rivers_out = rivers_out.to_crs(epsg=4326)\n",
    "\n",
    "nodes_for_df = [node[0:3] for node in nodes] # drop the extra columsn that will confuse a df\n",
    "for node in nodes:\n",
    "    nodes_for_df[node[0]].extend(list(node[3].values()))\n",
    "    nodes_for_df[node[0]].append(node[4:])\n",
    "nodes_df = pd.DataFrame(columns=['idx', 'x', 'y', 'elevation', 'runoff', 'flow_acc', 'arcs'], data=nodes_for_df)\n",
    "nodes_geometry = [Point(xy) for xy in zip(nodes_df['x'], nodes_df['y'])]\n",
    "nodes_out = gpd.GeoDataFrame(nodes_df, crs=rivers.crs, geometry=nodes_geometry)\n",
    "nodes_out = nodes_out.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_out['flow_acc_local'] = 0\n",
    "for index, node in nodes_out.iterrows():\n",
    "    actual_flow_acc = nodes_out.loc[index, 'flow_acc']\n",
    "    for arc in node['arcs']:\n",
    "        if network[arc][6] == index:\n",
    "            subtract = nodes_df.loc[network[arc][5], 'flow_acc']\n",
    "            actual_flow_acc -= subtract\n",
    "    nodes_df.loc[index, 'flow_acc_local'] = actual_flow_acc\n",
    "nodes_df.loc[nodes_df['flow_acc_local'] < 0, 'flow_acc_local'] = nodes_df['flow_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate rainfall runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the runoff from the rainfall using the rainfall-runoff method\n",
    "Calibrate against gscd annual values\n",
    "\"\"\"\n",
    "# precipitation_se = pd.read_excel('precip.xlsx', index_col=0, squeeze=True)\n",
    "# self.precipitation_df = pd.DataFrame(columns=precipitation_se.index, index=self.nodes_df.index)\n",
    "# for index, row in self.precipitation_df.iterrows():\n",
    "#    self.precipitation_df.loc[index] = precipitation_se\n",
    "\n",
    "default_precip_effectiveness = 0.5\n",
    "default_runoff_to_gw_fraction=0.5\n",
    "runoff_calibration_accuracy=0.2\n",
    "\n",
    "runoff_df = pd.DataFrame(columns=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], index=nodes_df.index)\n",
    "\n",
    "k_c = pd.read_excel('data/Uganda/k_c.xlsx', index_col=0)\n",
    "\n",
    "# formula from http://www.weap21.org/webhelp/hydrology.htm\n",
    "# for each point, calculate the runoff for each month, then compare to gscd annual value and modify params\n",
    "nodes_df['precip_effective'] = default_precip_effectiveness  # default starting values\n",
    "nodes_df['runoff_to_gw_fraction'] = default_runoff_to_gw_fraction\n",
    "for index, row in runoff_df.iterrows():\n",
    "    print('calibrate {}'.format(index))\n",
    "    counter = 0\n",
    "    while True:\n",
    "        for col in runoff_df:\n",
    "            et_ref = nodes_df.loc[index, \"et_ref\"]\n",
    "            # precip = self.precipitation_df.loc[index, col]\n",
    "            precip = nodes_df.loc[index, '{}{}'.format(\"precip\", col)] * \\\n",
    "                     3600 * 24 * days_per_month[col]\n",
    "            precip_avail_for_et = precip * nodes_df.loc[index, 'precip_effective']\n",
    "            et_potential = et_ref * k_c.loc[col, nodes_df.loc[index, \"land_type\"]]\n",
    "            runoff = max(0, precip_avail_for_et-et_potential) + \\\n",
    "                precip * (1-nodes_df.loc[index, 'precip_effective'])\n",
    "            runoff_to_surface = runoff * (1 - nodes_df.loc[index, 'runoff_to_gw_fraction'])\n",
    "\n",
    "            runoff_df.loc[index, col] = runoff_to_surface\n",
    "\n",
    "        ref_value = nodes_df.loc[index, \"gscd\"]\n",
    "        calc_value = runoff_df.loc[index].mean() * 12  # to compare with annual gscd\n",
    "\n",
    "        if counter > 10:\n",
    "            break\n",
    "        elif abs((calc_value - ref_value) / ref_value) < runoff_calibration_accuracy:\n",
    "            break\n",
    "        else:\n",
    "            counter += 1\n",
    "            nodes_df.loc[index, 'precip_effective'] *= 1 + sorted([-0.5, (calc_value - ref_value) / ref_value / 10, 0.5])[1]\n",
    "            nodes_df.loc[index, 'runoff_to_gw_fraction'] *= 1 + sorted([-0.5, (calc_value - ref_value) / ref_value / 10, 0.5])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Calculate discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_loss_factor=0.00001\n",
    "max_water_loss_fraction=0.2\n",
    "\n",
    "area = flow_acc.res[0] * flow_acc.res[1]\n",
    "\n",
    "# calculate self discharge for each node\n",
    "# Q [m3/s] = runoff [mm] * flowacc [number] * area [m2] / 8760 [h/year] * 3600 [s/h] * 1000 [mm/m]\n",
    "discharge_df = pd.DataFrame(columns=runoff_df.columns, index=runoff_df.index)\n",
    "for index, row in discharge_df.iterrows():\n",
    "    print('discharge {}'.format(index))\n",
    "    for col in discharge_df:\n",
    "        discharge_df.loc[index, col] = \\\n",
    "            runoff_df.loc[index, col]*nodes_df.loc[index, field_flow_acc_local] * \\\n",
    "            area / (24*days_per_month[col]*3600*1000)\n",
    "\n",
    "nodes_df['discharge_local'] = \\\n",
    "    nodes_df['gscd'] * nodes_df['flow_acc_local'] * area / (8760*3600*1000)\n",
    "nodes_df['discharge_accum'] = nodes_df['discharge_local']]\n",
    "\n",
    "# start from Shreve order 1, and contribute all discharges from upstream nodes to downstream nodes\n",
    "for so in range(1, max(network.T[7])+1):\n",
    "    for arc in network:\n",
    "        if arc[7] == so:\n",
    "            print('contribute {}'.format(arc[0]))\n",
    "            nodes_df.loc[arc[6], 'discharge_accum'] += \\\n",
    "                nodes_df.loc[arc[5], 'discharge_accum'] * \\\n",
    "                (1 - max(max_water_loss_fraction, water_loss_factor * arc[8]))\n",
    "            for col in discharge_df:\n",
    "            discharge_df.loc[arc[6], col] += \\\n",
    "                    discharge_df.loc[arc[5], col] * (1 - max(max_water_loss_fraction,\n",
    "                                                                  water_loss_factor * arc[8]))\n",
    "\n",
    "nodes_df['discharge_max'] = -99\n",
    "nodes_df['discharge_mean'] = -99\n",
    "nodes_df['discharge_min'] = -99\n",
    "for index, node in nodes_df.iterrows():\n",
    "    nodes_df.loc[index, 'discharge_max'] = discharge_df.loc[index].max()\n",
    "    nodes_df.loc[index, 'discharge_mean'] = discharge_df.loc[index].mean()\n",
    "    nodes_df.loc[index, 'discharge_min'] = discharge_df.loc[index].min()\n",
    "\n",
    "# add the discharge from the upstream node of each arc to that arc\n",
    "network_df = pd.DataFrame(network, columns=[field_arc_id, 'fx', 'fy', 'lx', 'ly',\n",
    "                                                      'nif', 'nil', field_shreve, 'arc_length'])\n",
    "network_df['discharge_accum'] = -99\n",
    "network_df['discharge_max'] = -99\n",
    "network_df['discharge_mean'] = -99\n",
    "network_df['discharge_min'] = -99\n",
    "for index, arc in network_df.iterrows():\n",
    "    network_df.loc[index, 'discharge_accum'] = \\\n",
    "        nodes_df[field_discharge_accumulated][arc['nif']]\n",
    "    network_df.loc[index, 'discharge_max'] = nodes_df['discharge_max'][arc['nif']]\n",
    "    network_df.loc[index, 'discharge_mean'] = nodes_df['discharge_mean'][arc['nif']]\n",
    "    network_df.loc[index, 'discharge_min'] = nodes_df['discharge_min'][arc['nif']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create hydropower points (EASY WAY!)\n",
    "And add in data from dem, gscd, land_type, et_ref, precip\n",
    "\n",
    "**Need to multiply GSCD with HydroSHEDS FlowAcc layer to get from mm/year to m3/sec**\n",
    "\n",
    "Start at the top of each river, get source GSCDxFlowAccxsquare size.\n",
    "NB: Make the contribution % dependent on slope (elevation change/distance)!\n",
    "\n",
    "Copy paste from HydroModeller:\n",
    "For each node, subtract the flow accumulation for all upstream nodes, so that we calculate it's 'self discharge' only for it's directly contributing area if anything goes negative, give its original flow_acc back.\n",
    "\n",
    "Then we assign discharges to the network and make it a property of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the point_interval in metres\n",
    "# This loops through each stream and adds points down it at the specified interval\n",
    "# And creates a dict with these new point geometries\n",
    "\n",
    "# At 20 deg South:\n",
    "# 1 degree = 110704 metres -> 1 minute = 1845 metres -> 1 second = 30.75 metres\n",
    "# River network is 15 second resolution = 461 metres\n",
    "# Therefore each up_cell size is\n",
    "cell_area = (110704/60/60*15)**2\n",
    "\n",
    "proj = pyproj.Proj(init='epsg:3395')  # Mercator\n",
    "\n",
    "point_interval = 1000  # how frequently to make points\n",
    "head_calc_distance = 2000  # how far upstream to look to calculate head\n",
    "rho = 1000\n",
    "g = 9.81\n",
    "n = 0.5\n",
    "\n",
    "hydro_points_dicts = []\n",
    "count = 0\n",
    "for index, row in rivers.iterrows():\n",
    "    geom = shape(row['geometry'])\n",
    "    length = geom.length\n",
    "    for i, distance in enumerate(range(0, int(length), point_interval)):\n",
    "        arcid = row['arcid']\n",
    "        up_cells = row['up_cells']\n",
    "        \n",
    "        point = Point(proj(*list(geom.interpolate(distance).coords)[0], inverse=True))\n",
    "        upstream_point = Point(proj(*list(geom.interpolate(distance - head_calc_distance).coords)[0], inverse=True))\n",
    "        \n",
    "        elevation = next(dem.sample(list(point.coords))).tolist()[0]\n",
    "        upstream_elevation = next(dem.sample(list(upstream_point.coords))).tolist()[0]\n",
    "        head = upstream_elevation - elevation\n",
    "        \n",
    "        runoff = next(gscd.sample(list(point.coords))).tolist()[0]\n",
    "        flowrate = runoff * up_cells * cell_area * (1/1000) * (1/(8760*3600))  # convert mm/year to m3/s\n",
    "        \n",
    "        power = rho*g*n*flowrate*head\n",
    "        \n",
    "        if head > 0 and flowrate > 0:\n",
    "            hydro_points_dicts.append({'arcid': arcid, 'elevation': elevation, \n",
    "                             'head': head, 'flowrate': flowrate, 'power': power, 'geometry': point})\n",
    "            \n",
    "        count += 1\n",
    "        if count % 10000 == 0: print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hydro_points to a GDF\n",
    "hydro_points = gpd.GeoDataFrame(hydro_points_dicts)\n",
    "hydro_points.crs = {'init' :'epsg:4326'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate hydropower (HARD WAY!)\n",
    "This is used in ADDITION to the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_t=0.88\n",
    "eta_g=0.96\n",
    "conv=0.6\n",
    "\n",
    "# transfer discharge values from the river to the points\n",
    "hydro_points['discharge_accum'] = -99\n",
    "hydro_points['discharge_max'] = -99\n",
    "hydro_points['discharge_mean'] = -99\n",
    "hydro_points['discharge_min'] = -99\n",
    "for index, row in points_df.iterrows():\n",
    "    hydro_points.loc[index, 'discharge_accum'] = \\\n",
    "        network_df.loc[points_df.loc[index, 'arcid'], 'discharge_accum']\n",
    "    hydro_points.loc[index, 'discharge_max'] = \\\n",
    "        network_df.loc[points_df.loc[index, 'arcid'], 'discharge_max']\n",
    "    hydro_points.loc[index, 'discharge_mean'] = \\\n",
    "        network_df.loc[points_df.loc[index, 'arcid'], 'discharge_mean']\n",
    "    hydro_points.loc[index, 'discharge_min'] = \\\n",
    "        network_df.loc[points_df.loc[index, 'arcid'], 'discharge_min']\n",
    "\n",
    "# calculate the power in watts based on Alex's formula\n",
    "hydro_points['power_accum'] = rho * g * eta_t * eta_g * conv * points_df['discharge_accum'] * points_df['head']\n",
    "hydro_points['power_max'] = rho * g * eta_t * eta_g * conv * points_df['discharge_max'] * points_df['head']\n",
    "hydro_points['power_mean'] = rho * g * eta_t * eta_g * conv * points_df['discharge_mean'] * points_df['head']\n",
    "hydro_points['power_min'] = rho * g * eta_t * eta_g * conv * points_df['discharge_min'] * points_df['head']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Convert the data back to GeoDataFrame and save as GeoPackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_out.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_points.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_out.to_file(out_rivers, driver='GPKG')\n",
    "nodes_out.to_file(out_nodes, driver='GPKG')\n",
    "hydro_points.to_file(out_hydro, driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
